from io import BytesIO, StringIO
from typing import Union, Optional, Callable

import streamlit as st

from src.config import ADMIN_USERNAME
from src.submissions.submissions_manager import SubmissionManager, SingleParticipantSubmissions

import pandas as pd
import numpy as np
import asyncio
import random
#from app import get_leaderboard, get_username
from src.display.leaderboard import Leaderboard
from src.config import (SUBMISSIONS_DIR, EVALUATOR_CLASS, EVALUATOR_KWARGS, PASSWORDS_DB_FILE,
                        ARGON2_KWARGS, ALLOWED_SUBMISSION_FILE_EXTENSION, MAX_NUM_USERS, ADMIN_USERNAME)
from src.evaluation.evaluator import Evaluator
import base64
from src.evaluation.gpteval import execute_eval

import random
import os

class SubmissionSidebar:
    def __init__(self, username: str, submission_manager: SubmissionManager,
                 submission_file_extension: Optional[str] = None,
                 submission_validator: Optional[Callable[[Union[StringIO, BytesIO]], bool]] = None):
        self.username = username
        self.submission_manager = submission_manager
        self.submission_file_extension = submission_file_extension
        self.submission_validator = submission_validator
        self.participant: SingleParticipantSubmissions = None
        self.file_uploader_key = f"file upload {username}"

    def init_participant(self):
        self.submission_manager.add_participant(self.username, exists_ok=True)
        self.participant = self.submission_manager.get_participant(self.username)

    def run_submission(self):
        st.sidebar.title(f"Hello {self.username}!")
        if self.username != ADMIN_USERNAME:
            st.sidebar.markdown("## Submit Your Results :fire:")
            self.submit()

    def submit(self):
        file_extension_suffix = f" (.{self.submission_file_extension})" if self.submission_file_extension else None
        submission_io_stream = st.sidebar.file_uploader("Upload your submission file" + file_extension_suffix,
                                                        type=self.submission_file_extension,
                                                        key=self.file_uploader_key)
        submission_name = st.sidebar.text_input('Submission name (optional):', value='', max_chars=30)
        if st.sidebar.button('Submit'):
            if submission_io_stream is None:
                st.sidebar.error('Please upload a submission file.')
            else:
                submission_failed = True
                with st.spinner('Uploading your submission...'):
                    # CSV„Éï„Ç°„Ç§„É´„ÅÆË™≠„ÅøËæº„Åø
                    data = pd.read_csv(submission_io_stream)
                    st.session_state['data'] = data.replace(np.nan, '', regex=True)
                    st.write(st.session_state['data'])
                    submission_failed = False

                    # if self.submission_validator is None or self.submission_validator(submission_io_stream):
                    #     print("üòéupload_submission", submission_io_stream, submission_name)
                    #     self._upload_submission(submission_io_stream, submission_name)
                    #     submission_failed = False
                if submission_failed:
                    st.sidebar.error("Upload failed. The submission file is not valid.")
                else:
                    st.sidebar.success("Upload successful!")
        
        # OK„Éú„Çø„É≥„ÇíË®≠ÁΩÆ
        if st.button('Start evaluation', type="primary"):
            if submission_io_stream is None:
                st.error('Please upload a submission file.')
            else:
                # # CSV„Éá„Éº„Çø„ÅÆÂá¶ÁêÜ
                json_result = asyncio.run(self._main("start"))
                self._upload_submission(submission_io_stream, submission_name, json_result)
                
                # 'scores'„ÅÆ„Éá„Éº„Çø„ÇíDataFrame„Å´Â§âÊèõ
                scores_df = pd.DataFrame(json_result['scores'])
                # CSV„Å´„Ç®„É≥„Ç≥„Éº„Éâ
                csvfile = scores_df.to_csv(index=False)
                b64 = base64.b64encode(csvfile.encode()).decode()  # Base64„Ç®„É≥„Ç≥„Éº„Éâ

                # „ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„É™„É≥„ÇØ„Çí‰ΩúÊàê
                href = f'<a href="data:file/csv;base64,{b64}" download="results.csv">Download Results</a>'
                st.markdown(href, unsafe_allow_html=True)

    def _upload_submission(self, io_stream: Union[BytesIO, StringIO], submission_name: Optional[str] = None, json_result=None):
        self.init_participant()
        # CSV „ÅÆ„Ç≥„Éî„Éº
        # JSON„Çí‰øùÂ≠ò„Åô„Çã„ÅÆ„ÅØ„Åì„Åì TODO
        self.participant.add_submission(io_stream, submission_name, self.submission_file_extension, json_result)
    
    # main coroutine
    async def _main(self, some_argument):
        # ÈùûÂêåÊúüÂá¶ÁêÜ„ÅÆÂÆüË°å
        average_score, each_rows = await self.process_csv(st.session_state['data'])
        
        # Ëß£ÊûêÁµêÊûú„ÅÆË°®Á§∫
        #if st.session_state['result'] is not None:
        if average_score is not None:
            # Show result
            st.write('Evaluation result:')
            st.write("average_score:")
            st.write(average_score)
            # record „ÅÆÂÄ§„ÅÆÂêàË®à„ÇíÁÆóÂá∫
            total_score = sum(average_score.values())
            st.write(f"total_score: {total_score:.3f}")

            # JSONÁî®„Éá„Éº„Çø
            data = {
                "scores": each_rows,
                "average_score": average_score,
                "total_score": total_score
            }

            return data


    # „Éá„Éº„ÇøÂá¶ÁêÜÈñ¢Êï∞
    async def process_csv(self, data):
        # ÈÄ≤Êçó„Éê„Éº„ÅÆÂàùÊúüÂåñ
        progress_bar = st.progress(0)
        status_text = st.empty()
        status1 = st.status("Evaluating...", expanded=True)
        average_score = 0
        # „Éá„Éº„ÇøË°åÊï∞
        total_rows = len(data)
        record = {"gpt_relevance": 0, "gpt_groundedness": 0, "gpt_similarity": 0, "gpt_fluency": 0, "ada_cosine_similarity": 0}
        #st.session_state['count'] = total_rows

        each_rows = []
        # ÂêÑË°å„Åî„Å®„Å´Âá¶ÁêÜ
        for i, row in data.iterrows():
            # „Çπ„ÉÜ„Éº„Çø„Çπ„ÅÆÊõ¥Êñ∞
            status_text.text(f'Evaluating: {i + 1}/{total_rows} rows')

            # Ë°å„ÅÆ„Éá„Éº„Çø„ÇíÂá¶ÁêÜ
            #processed_row = await self._execute_eval_test(row)
            processed_row = await execute_eval(row)
            each_rows.append(processed_row)
            status1.write(str(i) + " : " + str(processed_row))
            # ÈÄ≤Êçó„Éê„Éº„ÅÆÊõ¥Êñ∞
            progress_bar.progress((i + 1) / total_rows)

            # return_score „ÅÆÂêÑ„Ç≠„Éº„Å´ÂØæ„Åó„Å¶„ÄÅrecord „ÅÆÂØæÂøú„Åô„Çã„Ç≠„Éº„ÅÆÂÄ§„Å´Âä†ÁÆó
            for key, value in processed_row.items():
                if key in record:
                    record[key] += value

        # record „ÅÆÂêÑ„Ç≠„Éº„Çí„É¨„Ç≥„Éº„ÉâÊï∞„ÅßÈô§ÁÆó„Åó„Å¶Âπ≥Âùá„ÇíË®àÁÆó
        if total_rows > 0:
            average_score = {key: round(value / total_rows, 3) for key, value in record.items()}

        # „Çπ„ÉÜ„Éº„Çø„Çπ„ÅÆ„ÇØ„É™„Ç¢
        status_text.text('Evaluation complete')
        status1.update(label="Evaluation complete!", state="complete", expanded=False)
        return average_score, each_rows
